BB0 {
  R0.0 = blockIdx.x;
}
// Condition from BB0
if (!(R0.0 >= ConstMem(0, 388))) {
  BB1 {
    R2.0 = threadIdx.x;
  }
  // Condition from BB1
  if (!(R2.0 > 255)) {
    // Loop header BB2
    while (!(R2.2 >= 256)) {
      BB2 {
        shmem_u8[R2.1] = R2.1;
        R2.2 = R2.1 + ConstMem(0, 0);
        // 2 phi node(s) omitted
      }
    }
  }
  BB3 {
    __syncthreads();
  }
  // Condition from BB3
  if (!(P0.1)) {
    BB4 {
      R3.1 = abs(ConstMem(0, 360));
      R7.1 = RZ;
      R8.1 = i2f_rp(R3.1);
      R8.2 = rcp_approx(R8.1);
      R4.1 = R8.2 + 268435454;
      R5.1 = f2i_trunc_u32_ftz_ntz(R4.1);
      R4.2 = RZ;
      R2.4 = -R5.1;
      R9.1 = R2.4 * R3.1 + RZ;
      R2.5 = RZ;
      R6.1 = mul_hi_u32(R5.1, R9.1) + R4.2;
    }
    // Loop header BB5
    while (R2.7 != 256) {
      BB5 {
        R5.3 = abs(R2.6);
        R16.2 = shmem_u8[R2.6];
        R4.4 = abs(ConstMem(0, 360));
        P2.2 = R2.6 >= RZ;
        R6.3 = mul_hi_u32(R6.2, R5.3);
        R12.2 = i2f_rp(R4.4);
        R6.4 = -R6.3;
        R5.4 = R4.4 * R6.4 + R5.3;
        P1.5 = R3.2 > R5.4;
        R12.3 = rcp_approx(R12.2);
        if (!P1.5) R5.5 = R5.4 - R4.4;
        P1.6 = R3.2 > R5.5;
        R8.4 = R12.3 + 268435454;
        R9.3 = f2i_trunc_u32_ftz_ntz(R8.4);
        if (!P1.6) R5.6 = R5.5 - R4.4;
        P1.7 = RZ != ConstMem(0, 360);
        R6.5 = R5.6;
        R5.7 = ~ConstMem(0, 360);
        if (!P2.2) R6.6 = -R6.5;
        R6.7 = !P1.7 ? R5.7 : R6.6;
        R10.2 = R6.7 + ConstMem(0, 352);
        P2.3 = carry_u32_add3(R6.7, ConstMem(0, 352), RZ);
        R11.2 = lea_hi_x_sx32(R6.7, ConstMem(0, 356), 1, P2.3);
        R10.3 = *((uint8_t*)addr64(R10.2, R11.2));
        R3.3 = -R9.3;
        R12.4 = R2.6 + 1;
        R8.5 = RZ;
        R3.4 = R3.3 * R4.4 + RZ;
        R13.2 = abs(R12.4);
        P3.2 = R12.4 >= RZ;
        R6.8 = mul_hi_u32(R9.3, R3.4) + R8.5;
        R9.4 = R13.2;
        R3.5 = mul_hi_u32(R6.8, R9.4);
        R3.6 = -R3.5;
        R8.6 = R4.4 * R3.6 + R9.4;
        R3.7 = R4.4;
        P2.4 = R3.7 > R8.6;
        if (!P2.4) R8.7 = R8.6 - R4.4;
        P2.5 = R3.7 > R8.7;
        if (!P2.5) R8.8 = R8.7 - R4.4;
        if (!P3.2) R8.9 = -R8.8;
        R9.5 = !P1.7 ? R5.7 : R8.9;
        R8.10 = R9.5 + ConstMem(0, 352);
        P2.6 = carry_u32_add3(R9.5, ConstMem(0, 352), RZ);
        R9.6 = lea_hi_x_sx32(R9.5, ConstMem(0, 356), 1, P2.6);
        R9.7 = *((uint8_t*)addr64(R8.10, R9.6));
        R11.3 = R2.6 + 2;
        R13.3 = abs(R11.3);
        P3.3 = R11.3 >= RZ;
        R12.5 = mul_hi_u32(R6.8, R13.3);
        R12.6 = -R12.5;
        R12.7 = R4.4 * R12.6 + R13.3;
        P2.7 = R3.7 > R12.7;
        if (!P2.7) R12.8 = R12.7 - R4.4;
        P2.8 = R3.7 > R12.8;
        if (!P2.8) R12.9 = R12.8 - R4.4;
        if (!P3.3) R12.10 = -R12.9;
        R8.11 = !P1.7 ? R5.7 : R12.10;
        R12.11 = R8.11 + ConstMem(0, 352);
        P2.9 = carry_u32_add3(R8.11, ConstMem(0, 352), RZ);
        R13.4 = lea_hi_x_sx32(R8.11, ConstMem(0, 356), 1, P2.9);
        R8.12 = *((uint8_t*)addr64(R12.11, R13.4));
        R11.4 = R2.6 + 3;
        R15.2 = abs(R11.4);
        P3.4 = R11.4 >= RZ;
        R14.2 = mul_hi_u32(R6.8, R15.2);
        R14.3 = -R14.2;
        R14.4 = R4.4 * R14.3 + R15.2;
        P2.10 = R3.7 > R14.4;
        if (!P2.10) R14.5 = R14.4 - R4.4;
        P2.11 = R3.7 > R14.5;
        if (!P2.11) R14.6 = R14.5 - R4.4;
        if (!P3.4) R14.7 = -R14.6;
        R14.8 = !P1.7 ? R5.7 : R14.7;
        R12.12 = R10.3 + R7.2 + R16.2;
        R10.4 = R14.8 + ConstMem(0, 352);
        P2.12 = carry_u32_add3(R14.8, ConstMem(0, 352), RZ);
        R7.3 = R12.12 >> 31;
        R11.5 = lea_hi_x_sx32(R14.8, ConstMem(0, 356), 1, P2.12);
        R13.5 = hi32(R7.3 + (R12.12 << 8));
        R7.4 = *((uint8_t*)addr64(R10.4, R11.5));
        R13.6 = R13.5 & 4294967040;
        R17.2 = R12.12 - R13.6;
        R12.13 = R2.6 + 4;
        R13.7 = shmem_u8[R17.2];
        R15.3 = abs(R12.13);
        P3.5 = R12.13 >= RZ;
        R14.9 = mul_hi_u32(R6.8, R15.3);
        R14.10 = -R14.9;
        R14.11 = R4.4 * R14.10 + R15.3;
        P2.13 = R3.7 > R14.11;
        if (!P2.13) R14.12 = R14.11 - R4.4;
        P2.14 = R3.7 > R14.12;
        shmem_u8[R2.6] = R13.7;
        shmem_u8[R17.2] = R16.2;
        R18.2 = shmem_u8[R2.6 + 1];
        if (!P2.14) R14.13 = R14.12 - R4.4;
        if (!P3.5) R14.14 = -R14.13;
        R14.15 = !P1.7 ? R5.7 : R14.14;
        R10.5 = R14.15 + ConstMem(0, 352);
        P2.15 = carry_u32_add3(R14.15, ConstMem(0, 352), RZ);
        R11.6 = lea_hi_x_sx32(R14.15, ConstMem(0, 356), 1, P2.15);
        R12.14 = R9.7 + R17.2 + R18.2;
        R9.8 = R12.14 >> 31;
        R13.8 = hi32(R9.8 + (R12.14 << 8));
        R9.9 = *((uint8_t*)addr64(R10.5, R11.6));
        R13.9 = R13.8 & 4294967040;
        R17.3 = R12.14 - R13.9;
        R12.15 = R2.6 + 5;
        R13.10 = shmem_u8[R17.3];
        R15.4 = abs(R12.15);
        P3.6 = R12.15 >= RZ;
        R14.16 = mul_hi_u32(R6.8, R15.4);
        R14.17 = -R14.16;
        R14.18 = R4.4 * R14.17 + R15.4;
        P2.16 = R3.7 > R14.18;
        if (!P2.16) R14.19 = R14.18 - R4.4;
        P2.17 = R3.7 > R14.19;
        shmem_u8[R2.6 + 1] = R13.10;
        shmem_u8[R17.3] = R18.2;
        R16.3 = shmem_u8[R2.6 + 2];
        if (!P2.17) R14.20 = R14.19 - R4.4;
        if (!P3.6) R14.21 = -R14.20;
        R14.22 = !P1.7 ? R5.7 : R14.21;
        R10.6 = R14.22 + ConstMem(0, 352);
        P2.18 = carry_u32_add3(R14.22, ConstMem(0, 352), RZ);
        R11.7 = lea_hi_x_sx32(R14.22, ConstMem(0, 356), 1, P2.18);
        R12.16 = R8.12 + R17.3 + R16.3;
        R8.13 = *((uint8_t*)addr64(R10.6, R11.7));
        R13.11 = R12.16 >> 31;
        R13.12 = hi32(R13.11 + (R12.16 << 8));
        R13.13 = R13.12 & 4294967040;
        R17.4 = R12.16 - R13.13;
        R13.14 = shmem_u8[R17.4];
        R12.17 = R2.6 + 6;
        R15.5 = abs(R12.17);
        R14.23 = mul_hi_u32(R6.8, R15.5);
        R14.24 = -R14.23;
        R14.25 = R4.4 * R14.24 + R15.5;
        P2.19 = R3.7 > R14.25;
        shmem_u8[R2.6 + 2] = R13.14;
        shmem_u8[R17.4] = R16.3;
        R18.3 = shmem_u8[R2.6 + 3];
        if (!P2.19) R14.26 = R14.25 - R4.4;
        P3.7 = R12.17 >= RZ;
        P2.20 = R3.7 > R14.26;
        if (!P2.20) R14.27 = R14.26 - R4.4;
        if (!P3.7) R14.28 = -R14.27;
        R14.29 = !P1.7 ? R5.7 : R14.28;
        R10.7 = R14.29 + ConstMem(0, 352);
        P2.21 = carry_u32_add3(R14.29, ConstMem(0, 352), RZ);
        R12.18 = R7.4 + R17.4 + R18.3;
        R7.5 = R12.18 >> 31;
        R11.8 = lea_hi_x_sx32(R14.29, ConstMem(0, 356), 1, P2.21);
        R13.15 = hi32(R7.5 + (R12.18 << 8));
        R7.6 = *((uint8_t*)addr64(R10.7, R11.8));
        R13.16 = R13.15 & 4294967040;
        R16.4 = R12.18 - R13.16;
        R13.17 = shmem_u8[R16.4];
        R12.19 = R2.6 + 7;
        R15.6 = abs(R12.19);
        R14.30 = mul_hi_u32(R6.8, R15.6);
        R14.31 = -R14.30;
        R14.32 = R4.4 * R14.31 + R15.6;
        P2.22 = R3.7 > R14.32;
        shmem_u8[R2.6 + 3] = R13.17;
        shmem_u8[R16.4] = R18.3;
        R15.7 = shmem_u8[R2.6 + 4];
        if (!P2.22) R14.33 = R14.32 - R4.4;
        P3.8 = R12.19 >= RZ;
        P2.23 = R3.7 > R14.33;
        if (!P2.23) R14.34 = R14.33 - R4.4;
        if (!P3.8) R14.35 = -R14.34;
        R5.8 = !P1.7 ? R5.7 : R14.35;
        R4.5 = R5.8 + ConstMem(0, 352);
        P1.8 = carry_u32_add3(R5.8, ConstMem(0, 352), RZ);
        R9.10 = R9.9 + R16.4 + R15.7;
        R10.8 = R9.10 >> 31;
        R5.9 = lea_hi_x_sx32(R5.8, ConstMem(0, 356), 1, P1.8);
        R10.9 = hi32(R10.8 + (R9.10 << 8));
        R12.20 = *((uint8_t*)addr64(R4.5, R5.9));
        R10.10 = R10.9 & 4294967040;
        R10.11 = R9.10 - R10.10;
        R9.11 = shmem_u8[R10.11];
        shmem_u8[R2.6 + 4] = R9.11;
        shmem_u8[R10.11] = R15.7;
        R13.18 = shmem_u8[R2.6 + 5];
        R8.14 = R8.13 + R10.11 + R13.18;
        R11.9 = R8.14 >> 31;
        R11.10 = hi32(R11.9 + (R8.14 << 8));
        R11.11 = R11.10 & 4294967040;
        R8.15 = R8.14 - R11.11;
        R5.10 = shmem_u8[R8.15];
        shmem_u8[R2.6 + 5] = R5.10;
        shmem_u8[R8.15] = R13.18;
        R11.12 = shmem_u8[R2.6 + 6];
        R7.7 = R7.6 + R8.15 + R11.12;
        R4.6 = R7.7 >> 31;
        R4.7 = hi32(R4.6 + (R7.7 << 8));
        R4.8 = R4.7 & 4294967040;
        R4.9 = R7.7 - R4.8;
        R9.12 = shmem_u8[R4.9];
        shmem_u8[R2.6 + 6] = R9.12;
        shmem_u8[R4.9] = R11.12;
        R15.8 = shmem_u8[R2.6 + 7];
        R12.21 = R12.20 + R4.9 + R15.8;
        R5.11 = R12.21 >> 31;
        R5.12 = hi32(R5.11 + (R12.21 << 8));
        R5.13 = R5.12 & 4294967040;
        R7.8 = R12.21 - R5.13;
        R5.14 = shmem_u8[R7.8];
        shmem_u8[R2.6 + 7] = R5.14;
        shmem_u8[R7.8] = R15.8;
        R2.7 = R2.6 + 8;
        // 20 phi node(s) omitted
      }
    }
  }
  BB6 {
    __syncthreads();
  }
  // Condition from BB6
  if (!(P0.1)) {
    // Condition from BB7
    if (R7.10 >= 1) {
      // Condition from BB8
      if (R2.9 >= 3) {
        BB9 {
          R17.6 = R0.0 * ConstMem(0, 384) + RZ;
          R10.13 = R6.10 - ConstMem(0, 384);
          R9.15 = RZ;
          UR10.1 = uldc64(ConstMem(0, 368));
          R8.17 = R17.6 + 3;
          UR8.1 = uldc64(ConstMem(0, 376));
          R18.5 = R17.6 >> 31;
        }
        // Loop header BB10
        while (R10.15 != RZ) {
          BB10 {
            R2.11 = R8.18 - 3;
            P2.26 = R2.11 >= R7.11;
            R2.12 = R17.6 + UR10.2;
            P1.13 = carry_u32_add3(R17.6, UR10.2, RZ);
            R3.10 = R18.5 + UR11.1 + (P1.13 ? 1 : 0);
            if (!P2.26) R14.38 = *((uint8_t*)addr64(R2.12, R3.10));
            UR4.2 = UR4.1 + 1;
            UR5.2 = UR4.2 >> 31;
            UR5.3 = hi32(UR5.2 + (UR4.2 << 8));
            UR5.4 = UR5.3 & 4294967040;
            UR4.3 = UR4.2 - UR5.4;
            R12.24 = shmem_u8[UR4.3];
            R11.16 = R12.24 + R11.15;
            R4.12 = R11.16 >> 31;
            R4.13 = hi32(R4.12 + (R11.16 << 8));
            R4.14 = R4.13 & 4294967040;
            R19.2 = R11.16 - R4.14;
            R4.15 = R8.18 - 2;
            R11.17 = shmem_u8[R19.2];
            P1.14 = R4.15 >= R7.11;
            R4.16 = R17.6 + UR8.2;
            P3.11 = carry_u32_add3(R17.6, UR8.2, RZ);
            shmem_u8[UR4.3] = R11.17;
            shmem_u8[R19.2] = R12.24;
            R5.17 = shmem_u8[UR4.3];
            R5.18 = R12.24 + R5.17;
            if (!P2.26) R13.21 = R5.18 & 255;
            R5.19 = R18.5 + UR9.1 + (P3.11 ? 1 : 0);
            if (!P2.26) R13.22 = shmem_u8[R13.21];
            UR4.4 = UR4.3 + 1;
            UR5.5 = UR4.4 >> 31;
            UR5.6 = hi32(UR5.5 + (UR4.4 << 8));
            UR5.7 = UR5.6 & 4294967040;
            if (!P2.26) R15.11 = R14.38 ^ R13.22;
            if (!P2.26) *((uint8_t*)addr64(R4.16, R5.19)) = R15.11;
            if (!P1.14) R16.7 = *((uint8_t*)(addr64(R2.12, R3.10) + 1));
            UR4.5 = UR4.4 - UR5.7;
            R11.18 = shmem_u8[UR4.5];
            R12.25 = R19.2 + R11.18;
            R13.23 = R12.25 >> 31;
            R13.24 = hi32(R13.23 + (R12.25 << 8));
            R13.25 = R13.24 & 4294967040;
            R20.2 = R12.25 - R13.25;
            R12.26 = shmem_u8[R20.2];
            shmem_u8[UR4.5] = R12.26;
            shmem_u8[R20.2] = R11.18;
            R14.39 = shmem_u8[UR4.5];
            R13.26 = R11.18 + R14.39;
            R14.40 = R8.18 - 1;
            if (!P1.14) R13.27 = R13.26 & 255;
            P2.27 = R14.40 >= R7.11;
            if (!P1.14) R13.28 = shmem_u8[R13.27];
            UR4.6 = UR4.5 + 1;
            UR5.8 = UR4.6 >> 31;
            UR5.9 = hi32(UR5.8 + (UR4.6 << 8));
            UR5.10 = UR5.9 & 4294967040;
            UR4.7 = UR4.6 - UR5.10;
            R11.19 = shmem_u8[UR4.7];
            if (!P1.14) R15.12 = R16.7 ^ R13.28;
            if (!P1.14) *((uint8_t*)(addr64(R4.16, R5.19) + 1)) = R15.12;
            if (!P2.27) R16.8 = *((uint8_t*)(addr64(R2.12, R3.10) + 2));
            R12.27 = R20.2 + R11.19;
            P1.15 = R8.18 >= R7.11;
            R13.29 = R12.27 >> 31;
            R13.30 = hi32(R13.29 + (R12.27 << 8));
            R13.31 = R13.30 & 4294967040;
            R19.3 = R12.27 - R13.31;
            R12.28 = shmem_u8[R19.3];
            shmem_u8[UR4.7] = R12.28;
            shmem_u8[R19.3] = R11.19;
            R14.41 = shmem_u8[UR4.7];
            R13.32 = R11.19 + R14.41;
            if (!P2.27) R13.33 = R13.32 & 255;
            if (!P2.27) R13.34 = shmem_u8[R13.33];
            UR4.8 = UR4.7 + 1;
            UR5.11 = UR4.8 >> 31;
            UR5.12 = hi32(UR5.11 + (UR4.8 << 8));
            UR5.13 = UR5.12 & 4294967040;
            UR4.9 = UR4.8 - UR5.13;
            R12.29 = shmem_u8[UR4.9];
            if (!P2.27) R15.13 = R16.8 ^ R13.34;
            if (!P2.27) *((uint8_t*)(addr64(R4.16, R5.19) + 2)) = R15.13;
            if (!P1.15) R16.9 = *((uint8_t*)(addr64(R2.12, R3.10) + 3));
            R11.20 = R19.3 + R12.29;
            R10.15 = R10.14 + 4;
            UR8.3 = UR8.2 + 4;
            UP0.2 = UR8.3 + 4;
            R9.17 = R9.16 + 4;
            UR10.3 = UR10.2 + 4;
            UP1.2 = UR10.3 + 4;
            R14.42 = R11.20 >> 31;
            UR9.2 = URZ + UR9.1 + (UP0.2 ? 1 : 0);
            R8.19 = R8.18 + 4;
            UR11.2 = URZ + UR11.1 + (UP1.2 ? 1 : 0);
            R14.43 = hi32(R14.42 + (R11.20 << 8));
            R14.44 = R14.43 & 4294967040;
            R11.21 = R11.20 - R14.44;
            R2.13 = shmem_u8[R11.21];
            shmem_u8[UR4.9] = R2.13;
            shmem_u8[R11.21] = R12.29;
            R3.11 = shmem_u8[UR4.9];
            R3.12 = R12.29 + R3.11;
            if (!P1.15) R3.13 = R3.12 & 255;
            if (!P1.15) R3.14 = shmem_u8[R3.13];
            if (!P1.15) R13.35 = R16.9 ^ R3.14;
            if (!P1.15) *((uint8_t*)(addr64(R4.16, R5.19) + 3)) = R13.35;
            // 26 phi node(s) omitted
          }
        }
      }
      // Condition from BB11
      if (P0.3) {
        BB12 {
          R0.1 = R0.0 * ConstMem(0, 384) + R9.18;
          R12.31 = R0.1 + ConstMem(0, 376);
          P0.4 = carry_u32_add3(R0.1, ConstMem(0, 376), RZ);
          R9.19 = R0.1 + ConstMem(0, 368);
          P1.18 = carry_u32_add3(R0.1, ConstMem(0, 368), RZ);
          R2.15 = R0.1 >> 31;
          R13.37 = R2.15 + ConstMem(0, 380) + (P0.4 ? 1 : 0);
          R10.17 = R2.15 + ConstMem(0, 372) + (P1.18 ? 1 : 0);
        }
        // Loop header BB13
        while (R6.12 != RZ) {
          BB13 {
            P0.6 = R0.2 >= R7.11;
            if (!P0.6) R2.17 = R9.20;
            if (!P0.6) R3.17 = R10.18;
            if (!P0.6) R5.22 = *((uint8_t*)addr64(R2.17, R3.17));
            UR4.12 = UR4.11 + 1;
            R6.12 = R6.11 - 1;
            R9.21 = R9.20 + 1;
            P2.30 = carry_u32_add3(R9.21, 1, RZ);
            UR5.16 = UR4.12 >> 31;
            R0.3 = R0.2 + 1;
            UR5.17 = hi32(UR5.16 + (UR4.12 << 8));
            R10.19 = R10.18 + (P2.30 ? 1 : 0);
            UR5.18 = UR5.17 & 4294967040;
            UR4.13 = UR4.12 - UR5.18;
            R4.19 = shmem_u8[UR4.13];
            R11.24 = R4.19 + R11.23;
            R8.22 = R11.24 >> 31;
            R8.23 = hi32(R8.22 + (R11.24 << 8));
            R8.24 = R8.23 & 4294967040;
            R11.25 = R11.24 - R8.24;
            R2.18 = shmem_u8[R11.25];
            shmem_u8[UR4.13] = R2.18;
            shmem_u8[R11.25] = R4.19;
            R3.18 = shmem_u8[UR4.13];
            if (!P0.6) R2.19 = R12.32;
            R12.33 = R12.32 + 1;
            P1.20 = carry_u32_add3(R12.33, 1, RZ);
            R3.19 = R4.19 + R3.18;
            if (!P0.6) R3.20 = R3.19 & 255;
            if (!P0.6) R8.25 = shmem_u8[R3.20];
            if (!P0.6) R3.21 = R13.38;
            R13.39 = R13.38 + (P1.20 ? 1 : 0);
            if (!P0.6) R5.23 = R5.22 ^ R8.25;
            if (!P0.6) *((uint8_t*)addr64(R2.19, R3.21)) = R5.23;
            // 17 phi node(s) omitted
          }
        }
      }
    }
  }
}
